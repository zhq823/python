<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>框架完善--使用线程池实现异步以及并发控制 | 爬虫课程</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-prism/prism-solarizedlight.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../../爬虫框架开发/4.框架功能完善/11.框架完善--使用协程池实现异步以及并发控制.html" />
    
    
    <link rel="prev" href="../../爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="3.3.10"
        data-chapter-title="框架完善--使用线程池实现异步以及并发控制"
        data-filepath="爬虫框架开发/4.框架功能完善/10.框架完善--使用线程池实现异步以及并发控制.md"
        data-basepath="../.."
        data-revision="Wed May 23 2018 13:46:54 GMT+0800 (CST)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="爬虫入门/index.html">
            
                
                    <a href="../../爬虫入门/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        爬虫入门
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="爬虫入门/1.爬虫的基础知识/index.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫的基础知识
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="爬虫入门/1.爬虫的基础知识/1.爬虫的基础概念.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/1.爬虫的基础概念.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.1.</b>
                        
                        爬虫的定义和使用场景
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="爬虫入门/1.爬虫的基础知识/2.爬虫的分类和爬虫流程.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/2.爬虫的分类和爬虫流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.2.</b>
                        
                        爬虫的分类和爬虫的流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.3" data-path="爬虫入门/1.爬虫的基础知识/3.复习http和https.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/3.复习http和https.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.3.</b>
                        
                        http和https的复习
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.4" data-path="爬虫入门/1.爬虫的基础知识/4.字符串相关的复习.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/4.字符串相关的复习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.4.</b>
                        
                        字符串相关的复习
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="爬虫入门/2.requests模块的使用/index.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        requests模块的使用
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="爬虫入门/2.requests模块的使用/1.requests模块的基本使用.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/1.requests模块的基本使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.1.</b>
                        
                        requests模块的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="爬虫入门/2.requests模块的使用/2.requests模块的深入使用.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/2.requests模块的深入使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.2.</b>
                        
                        requests模块的深入使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="爬虫入门/2.requests模块的使用/3.requests模块处理cookie.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/3.requests模块处理cookie.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.3.</b>
                        
                        requests模块处理cookie
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="爬虫入门/2.requests模块的使用/4.requests模块的其他方法.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/4.requests模块的其他方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.4.</b>
                        
                        requests的其他方法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="爬虫入门/2.requests模块的使用/5.chrome浏览器使用方法介绍.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/5.chrome浏览器使用方法介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.5.</b>
                        
                        chrome浏览器使用方法介绍
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="爬虫入门/3.数据提取方法/index.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        数据提取方法
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="爬虫入门/3.数据提取方法/1.数据提取的概念和数据分类.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/1.数据提取的概念和数据分类.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.1.</b>
                        
                        数据提取的概念和数据分类
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="爬虫入门/3.数据提取方法/2.数据提取之json.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/2.数据提取之json.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.2.</b>
                        
                        数据提取之json
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="爬虫入门/3.数据提取方法/3.数据提取之正则.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/3.数据提取之正则.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.3.</b>
                        
                        数据提取之正则
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="爬虫入门/3.数据提取方法/4.xpath和lxml类库.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/4.xpath和lxml类库.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.4.</b>
                        
                        数据提取之xpath
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="爬虫入门/3.数据提取方法/5.lxml模块的学习.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/5.lxml模块的学习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.5.</b>
                        
                        数据提取之lxml
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="爬虫入门/3.数据提取方法/6.实现更快的爬虫.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/6.实现更快的爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.6.</b>
                        
                        多进程多线程爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="爬虫入门/3.数据提取方法/7.实现更快的爬虫（二）.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/7.实现更快的爬虫（二）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.7.</b>
                        
                        通过线程池实现爬虫
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="爬虫提高/index.html">
            
                
                    <a href="../../爬虫提高/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        爬虫提高
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="爬虫提高/1.selenium/index.html">
            
                
                    <a href="../../爬虫提高/1.selenium/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        selenium的学习
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="爬虫提高/1.selenium/1.常见的反爬手段和解决思路.html">
            
                
                    <a href="../../爬虫提高/1.selenium/1.常见的反爬手段和解决思路.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.1.</b>
                        
                        常见的反爬手段和解决思路
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="爬虫提高/1.selenium/2.selenium的使用.html">
            
                
                    <a href="../../爬虫提高/1.selenium/2.selenium的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.2.</b>
                        
                        selenium的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="爬虫提高/1.selenium/3.打码平台的使用.html">
            
                
                    <a href="../../爬虫提高/1.selenium/3.打码平台的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.3.</b>
                        
                        打码平台的使用
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="爬虫提高/2.MONGODB数据库/index.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        MONGODB数据库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.2.1" data-path="爬虫提高/2.MONGODB数据库/1.mongodb的介绍和安装.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/1.mongodb的介绍和安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.1.</b>
                        
                        mongodb的介绍和安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.2" data-path="爬虫提高/2.MONGODB数据库/2.mongodb的基本使用.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/2.mongodb的基本使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.2.</b>
                        
                        mongodb的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.3" data-path="爬虫提高/2.MONGODB数据库/3.mongodb的聚合操作.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/3.mongodb的聚合操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.3.</b>
                        
                        mongodb的聚合操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.4" data-path="爬虫提高/2.MONGODB数据库/4.mongodb的索引和备份恢复.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/4.mongodb的索引和备份恢复.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.4.</b>
                        
                        mongodb的索引和备份恢复
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.5" data-path="爬虫提高/2.MONGODB数据库/5.mongodb和python的交互.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/5.mongodb和python的交互.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.5.</b>
                        
                        mongodb和python交互
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="爬虫提高/3.scrapy/index.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        scrapy框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="爬虫提高/3.scrapy/1.scrapy的基础概念和流程.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/1.scrapy的基础概念和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.1.</b>
                        
                        scrapy的基础概念和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="爬虫提高/3.scrapy/2.scrapy的入门使用（一）.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/2.scrapy的入门使用（一）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.2.</b>
                        
                        scrapy的入门使用(一)
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.3" data-path="爬虫提高/3.scrapy/3.scrapy的入门使用（二）.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/3.scrapy的入门使用（二）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.3.</b>
                        
                        scrapy的入门使用(二)
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.4" data-path="爬虫提高/3.scrapy/4.scrapy的深入使用.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/4.scrapy的深入使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.4.</b>
                        
                        scrapy的深入使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.5" data-path="爬虫提高/3.scrapy/5.crawlspider类的使用.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/5.crawlspider类的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.5.</b>
                        
                        crawlspider类的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.6" data-path="爬虫提高/3.scrapy/6.下载中间件和模拟登陆.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/6.下载中间件和模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.6.</b>
                        
                        下载中间件和模拟登陆
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="爬虫提高/4.scrapy_redis/index.html">
            
                
                    <a href="../../爬虫提高/4.scrapy_redis/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        scrapy_redis
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.4.1" data-path="爬虫提高/4.scrapy_redis/1.scrapy_redis实现增量式爬虫.html">
            
                
                    <a href="../../爬虫提高/4.scrapy_redis/1.scrapy_redis实现增量式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.1.</b>
                        
                        scrapy_redis实现增量式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.2" data-path="爬虫提高/4.scrapy_redis/2.scrapy_redis实现分布式爬虫.html">
            
                
                    <a href="../../爬虫提高/4.scrapy_redis/2.scrapy_redis实现分布式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.2.</b>
                        
                        scrapy_redis实现分布式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.3" data-path="爬虫提高/4.scrapy_redis/3.crontab爬虫定时启动.html">
            
                
                    <a href="../../爬虫提高/4.scrapy_redis/3.crontab爬虫定时启动.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.3.</b>
                        
                        crontab爬虫定时启动
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="爬虫框架开发/index.html">
            
                
                    <a href="../../爬虫框架开发/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        爬虫框架开发
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="爬虫框架开发/1.爬虫框架开发分析/index.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        爬虫框架开发分析
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="爬虫框架开发/1.爬虫框架开发分析/1.了解框架.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/1.了解框架.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.1.</b>
                        
                        了解框架
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="爬虫框架开发/1.爬虫框架开发分析/2.框架设计思路分析.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/2.框架设计思路分析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.2.</b>
                        
                        框架设计思路分析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="爬虫框架开发/1.爬虫框架开发分析/3.框架代码雏形结构.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/3.框架代码雏形结构.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.3.</b>
                        
                        雏形代码结构
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="爬虫框架开发/2.框架雏形实现/index.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        框架雏形实现
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.2.1" data-path="爬虫框架开发/2.框架雏形实现/1.框架雏形--http模块和item模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/1.框架雏形--http模块和item模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.1.</b>
                        
                        框架雏形--http模块和item模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.2" data-path="爬虫框架开发/2.框架雏形实现/2.框架雏形--核心模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/2.框架雏形--核心模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.2.</b>
                        
                        框架雏形--核心模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.3" data-path="爬虫框架开发/2.框架雏形实现/3.框架安装.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/3.框架安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.3.</b>
                        
                        框架安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.4" data-path="爬虫框架开发/2.框架雏形实现/4.框架运行--main.py.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/4.框架运行--main.py.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.4.</b>
                        
                        框架运行--main.py
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.5" data-path="爬虫框架开发/2.框架雏形实现/5.框架雏形--中间件模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/5.框架雏形--中间件模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.5.</b>
                        
                        框架雏形--中间件
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="爬虫框架开发/4.框架功能完善/index.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        框架功能完善
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1" data-path="爬虫框架开发/4.框架功能完善/1.框架完善--日志模块使用.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/1.框架完善--日志模块使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.1.</b>
                        
                        框架完善--日志模块使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.2" data-path="爬虫框架开发/4.框架功能完善/2.框架完善--配置文件实现.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/2.框架完善--配置文件实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.2.</b>
                        
                        框架完善--配置文件实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.3" data-path="爬虫框架开发/4.框架功能完善/3.框架完善--多爬虫实现之一--多请求.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/3.框架完善--多爬虫实现之一--多请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.3.</b>
                        
                        框架完善--多爬虫实现之一--多请求
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.4" data-path="爬虫框架开发/4.框架功能完善/4.框架完善--多爬虫实现之二--多个解析函数.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/4.框架完善--多爬虫实现之二--多个解析函数.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.4.</b>
                        
                        框架完善--多爬虫实现之二--多个解析函数
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.5" data-path="爬虫框架开发/4.框架功能完善/5.框架完善--多爬虫实现之三--多爬虫文件.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/5.框架完善--多爬虫实现之三--多爬虫文件.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.5.</b>
                        
                        框架完善--多爬虫实现之三--多爬虫文件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.6" data-path="爬虫框架开发/4.框架功能完善/6.框架完善--实现多个管道.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/6.框架完善--实现多个管道.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.6.</b>
                        
                        框架完善--实现多个管道
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.7" data-path="爬虫框架开发/4.框架功能完善/7.框架完善--实现多个中间件.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/7.框架完善--实现多个中间件.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.7.</b>
                        
                        框架完善--实现多个中间件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.8" data-path="爬虫框架开发/4.框架功能完善/8.框架完善--实现动态模块导入.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/8.框架完善--实现动态模块导入.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.8.</b>
                        
                        框架完善--实现动态模块导入
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.9" data-path="爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.9.</b>
                        
                        框架完善--实现请求去重
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="3.3.10" data-path="爬虫框架开发/4.框架功能完善/10.框架完善--使用线程池实现异步以及并发控制.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/10.框架完善--使用线程池实现异步以及并发控制.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.10.</b>
                        
                        框架完善--使用线程池实现异步以及并发控制
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.11" data-path="爬虫框架开发/4.框架功能完善/11.框架完善--使用协程池实现异步以及并发控制.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/11.框架完善--使用协程池实现异步以及并发控制.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.11.</b>
                        
                        框架完善--使用协程池实现异步以及并发控制
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="爬虫框架开发/5.框架功能升级/index.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        框架功能升级
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.4.1" data-path="爬虫框架开发/5.框架功能升级/1.框架升级--分布式爬虫设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/1.框架升级--分布式爬虫设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.1.</b>
                        
                        框架升级--分布式爬虫设计原理及其实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4.2" data-path="爬虫框架开发/5.框架功能升级/2.框架升级--增量爬虫设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/2.框架升级--增量爬虫设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.2.</b>
                        
                        框架升级--增量爬虫设计原理及其实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4.3" data-path="爬虫框架开发/5.框架功能升级/3.框架升级--断点续爬设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/3.框架升级--断点续爬设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.3.</b>
                        
                        框架升级--断点续爬设计原理及其实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4.4" data-path="爬虫框架开发/5.框架功能升级/4.框架可以改进的内容.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/4.框架可以改进的内容.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.4.</b>
                        
                        框架升级--框架可以改进的内容
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="爬虫框架开发/6.项目实战/index.html">
            
                
                    <a href="../../爬虫框架开发/6.项目实战/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.</b>
                        
                        项目实战
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="扩展阅读/index.html">
            
                
                    <a href="../../扩展阅读/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        扩展阅读
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="扩展阅读/1.ascii和unicode以及utf-8.html">
            
                
                    <a href="../../扩展阅读/1.ascii和unicode以及utf-8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        ascii、unicode和utf-8的起源
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="扩展阅读/charles使用指南.html">
            
                
                    <a href="../../扩展阅读/charles使用指南.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        charles使用指南
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="参考代码/index.html">
            
                
                    <a href="../../参考代码/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        参考代码
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="参考代码/python爬虫中多线程多进程代码实现.html">
            
                
                    <a href="../../参考代码/python爬虫中多线程多进程代码实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        爬虫中多线程多进程代码实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="参考代码/云打码.html">
            
                
                    <a href="../../参考代码/云打码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        云打码的使用
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../" >爬虫课程</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="&#x5229;&#x7528;&#x7EBF;&#x7A0B;&#x6C60;&#x5B9E;&#x73B0;&#x5F02;&#x6B65;">&#x5229;&#x7528;&#x7EBF;&#x7A0B;&#x6C60;&#x5B9E;&#x73B0;&#x5F02;&#x6B65;</h1>
<h2 id="&#x76EE;&#x6807;">&#x76EE;&#x6807;</h2>
<ul>
<li>&#x638C;&#x63E1;&#x7EBF;&#x7A0B;&#x6C60;&#x7684;&#x4F7F;&#x7528;</li>
<li>&#x4F7F;&#x7528;&#x591A;&#x7EBF;&#x7A0B;&#x91CD;&#x6784;&#x4EE3;&#x7801;</li>
</ul>
<h2 id="1-&#x5F02;&#x6B65;&#x4EFB;&#x52A1;&#x5206;&#x6790;&#xFF1A;">1. &#x5F02;&#x6B65;&#x4EFB;&#x52A1;&#x5206;&#x6790;&#xFF1A;</h2>
<h3 id="11-&#x5728;&#x5F15;&#x64CE;&#x4E2D;&#xFF0C;&#x5B9E;&#x73B0;&#x7684;&#x4E3B;&#x8981;&#x529F;&#x80FD;&#x5982;&#x4E0B;&#x56FE;&#xFF0C;">1.1. &#x5728;&#x5F15;&#x64CE;&#x4E2D;&#xFF0C;&#x5B9E;&#x73B0;&#x7684;&#x4E3B;&#x8981;&#x529F;&#x80FD;&#x5982;&#x4E0B;&#x56FE;&#xFF0C;</h3>
<ul>
<li>&#x4E0A;&#x9762;&#x7684;&#x65B9;&#x6846;&#x4E2D;&#x662F;&#x5173;&#x4E8E;start_urls&#x4E2D;&#x7684;&#x8BF7;&#x6C42;&#x5904;&#x7406;</li>
<li>&#x4E0B;&#x9762;&#x7684;&#x65B9;&#x6846;&#x4E2D;&#x662F;&#x4E00;&#x4E2A;&#x8BF7;&#x6C42;&#x4ECE;&#x8C03;&#x5EA6;&#x5668;&#x53D6;&#x51FA;&#x8BF7;&#x6C42;&#xFF0C;&#x8FDB;&#x884C;&#x4E0B;&#x8F7D;&#x4E4B;&#x540E;&#x4EA4;&#x7ED9;&#x722C;&#x866B;&#x89E3;&#x6790;&#x518D;&#x4EA4;&#x7ED9;&#x7BA1;&#x9053;&#x7684;&#x8FC7;&#x7A0B;
&#x5728;&#x4EE5;&#x4E0A;&#x4E24;&#x4E2A;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x4ED6;&#x4EEC;&#x4E4B;&#x95F4;&#x6CA1;&#x6709;&#x76F4;&#x63A5;&#x7684;&#x8054;&#x7CFB;&#xFF0C;&#x90FD;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x5F02;&#x6B65;&#x591A;&#x7EBF;&#x7A0B;&#x7684;&#x65B9;&#x5F0F;&#x5206;&#x522B;&#x5B9E;&#x73B0;&#xFF0C;&#x52A0;&#x5FEB;&#x7A0B;&#x5E8F;&#x6267;&#x884C;&#x7684;&#x901F;&#x5EA6;
<img src="../images/&#x5F02;&#x6B65;&#x4EFB;&#x52A1;&#x5206;&#x6790;.png" alt="&#x5F02;&#x6B65;&#x4EFB;&#x52A1;&#x5206;&#x6790;"></li>
</ul>
<h3 id="12-&#x90A3;&#x4E48;&#x5177;&#x4F53;&#x8BE5;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x8BE5;&#x903B;&#x8F91;">1.2 &#x90A3;&#x4E48;&#x5177;&#x4F53;&#x8BE5;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x8BE5;&#x903B;&#x8F91;</h3>
<ul>
<li>multiprocessing.dummy &#x63D0;&#x4F9B;&#x7684;Pool &#x7C7B;&#x5177;&#x6709;apply_async&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x80FD;&#x591F;&#x5F02;&#x6B65;&#x7684;&#x6267;&#x884C;&#x8BA9;&#x4ED6;&#x8FD0;&#x884C;&#x7684;&#x51FD;&#x6570;</li>
<li>apply_async&#x65B9;&#x6CD5;&#x80FD;&#x591F;&#x63A5;&#x6536;&#x4E00;&#x4E2A;callback&#xFF0C;&#x5373;&#x5176;&#x4E2D;&#x7684;&#x51FD;&#x6570;&#x6267;&#x884C;&#x5B8C;&#x6210;&#x4E4B;&#x540E;&#x7EE7;&#x7EED;&#x4F1A;&#x505A;&#x7684;&#x4E8B;&#x60C5;&#xFF0C;&#x5728;&#x8FD9;&#x91CC;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;callback&#xFF0C;&#x5176;&#x4E2D;&#x8BA9;&#x4ED6;&#x7EE7;&#x7EED;&#x6267;&#x884C;&#x4E0A;&#x56FE;&#x4E2D;&#x4E0B;&#x65B9;&#x6846;&#x7684;&#x4EFB;&#x52A1;&#xFF0C;&#x540C;&#x65F6;&#x7ED9;&#x4ED6;&#x4E00;&#x4E2A;&#x505C;&#x6B62;&#x6761;&#x4EF6;&#xFF0C;</li>
</ul>
<h2 id="2-&#x5229;&#x7528;&#x56DE;&#x8C03;&#x5B9E;&#x73B0;&#x5FAA;&#x73AF;">2. &#x5229;&#x7528;&#x56DE;&#x8C03;&#x5B9E;&#x73B0;&#x5FAA;&#x73AF;</h2>
<p>&#x5229;&#x7528;&#x56DE;&#x8C03;&#x5B9E;&#x73B0;&#x9012;&#x5F52;&#xFF0C;&#x53EF;&#x4EE5;&#x8FBE;&#x5230;&#x5FAA;&#x73AF;&#x7684;&#x76EE;&#x7684;</p>
<pre><code class="lang-Python"># scrapy_plus/core/engine.py
import time
from multiprocessing.dummy import Pool    # &#x5BFC;&#x5165;&#x7EBF;&#x7A0B;&#x6C60;&#x5BF9;&#x8C61;
import importlib
from datetime import datetime

from scrapy_plus.http.request import Request    # &#x5BFC;&#x5165;Request&#x5BF9;&#x8C61;
from scrapy_plus.utils.log import logger    # &#x5BFC;&#x5165;logger
from scrapy_plus.conf import settings

from .scheduler import Scheduler
from .downloader import Downloader


class Engine(object):
    &apos;&apos;&apos;
    a. &#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x6574;&#x4E2A;&#x7684;&#x7A0B;&#x5E8F;&#x7684;&#x5165;&#x53E3;
    b. &#x4F9D;&#x6B21;&#x8C03;&#x7528;&#x5176;&#x4ED6;&#x7EC4;&#x4EF6;&#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x7684;&#x63A5;&#x53E3;&#xFF0C;&#x5B9E;&#x73B0;&#x6574;&#x4E2A;&#x6846;&#x67B6;&#x7684;&#x8FD0;&#x4F5C;(&#x9A71;&#x52A8;)
    &apos;&apos;&apos;

    def __init__(self):

        self.scheduler = Scheduler()    # &#x521D;&#x59CB;&#x5316;&#x8C03;&#x5EA6;&#x5668;&#x5BF9;&#x8C61;
        self.downloader = Downloader()    # &#x521D;&#x59CB;&#x5316;&#x4E0B;&#x8F7D;&#x5668;&#x5BF9;&#x8C61;

        self.spiders = self._auto_import_instances(settings.SPIDERS, True)  # &#x52A8;&#x6001;&#x5BFC;&#x5165;&#x5E76;&#x5B9E;&#x4F8B;&#x5316;&#x722C;&#x866B;&#x5BF9;&#x8C61;
        self.pipelines = self._auto_import_instances(settings.PIPELINES)  # &#x52A8;&#x6001;&#x5BFC;&#x5165;&#x5E76;&#x5B9E;&#x4F8B;&#x5316;&#x7BA1;&#x9053;&#x5BF9;&#x8C61;
        self.spider_mids = self._auto_import_instances(settings.SPIDER_MIDDLEWARES)  # &#x52A8;&#x6001;&#x5BFC;&#x5165;&#x5E76;&#x5B9E;&#x4F8B;&#x5316;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x5BF9;&#x8C61;
        self.downloader_mids = self._auto_import_instances(settings.DOWNLOADER_MIDDLEWARES)  # &#x52A8;&#x6001;&#x5BFC;&#x5165;&#x5E76;&#x5B9E;&#x4F8B;&#x5316;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x5BF9;&#x8C61;

        self.total_response_number = 0

        self.pool = Pool()  # &#x521B;&#x5EFA;&#x7EBF;&#x7A0B;&#x6C60;&#x5BF9;&#x8C61;
        self.running = False  # &#x8BB0;&#x5F55;&#x662F;&#x5426;&#x9000;&#x51FA;&#x7A0B;&#x5E8F;&#x7684;&#x72B6;&#x6001;

    def start(self):
        &apos;&apos;&apos;&#x542F;&#x52A8;&#x6574;&#x4E2A;&#x5F15;&#x64CE;&apos;&apos;&apos;
        start = datetime.now()  # &#x8D77;&#x59CB;&#x65F6;&#x95F4;
        logger.info(&quot;&#x5F00;&#x59CB;&#x8FD0;&#x884C;&#x65F6;&#x95F4;&#xFF1A;%s&quot; % start)  # &#x4F7F;&#x7528;&#x65E5;&#x5FD7;&#x8BB0;&#x5F55;&#x8D77;&#x59CB;&#x8FD0;&#x884C;&#x65F6;&#x95F4;
        self._start_engine()
        stop = datetime.now()  # &#x7ED3;&#x675F;&#x65F6;&#x95F4;
        logger.info(&quot;&#x5F00;&#x59CB;&#x8FD0;&#x884C;&#x65F6;&#x95F4;&#xFF1A;%s&quot; % stop)  # &#x4F7F;&#x7528;&#x65E5;&#x5FD7;&#x8BB0;&#x5F55;&#x7ED3;&#x675F;&#x8FD0;&#x884C;&#x65F6;&#x95F4;
        logger.info(&quot;&#x8017;&#x65F6;&#xFF1A;%.2f&quot; % (stop - start).total_seconds())  # &#x4F7F;&#x7528;&#x65E5;&#x5FD7;&#x8BB0;&#x5F55;&#x8FD0;&#x884C;&#x8017;&#x65F6;

    def _start_requests(self):
        &apos;&apos;&apos;&#x5411;&#x8C03;&#x5EA6;&#x5668;&#x6DFB;&#x52A0;&#x521D;&#x59CB;&#x8BF7;&#x6C42;&apos;&apos;&apos;
        # 1. &#x722C;&#x866B;&#x6A21;&#x5757;&#x53D1;&#x51FA;&#x521D;&#x59CB;&#x8BF7;&#x6C42;
        for spider_name, spider in self.spiders.items():
            for start_request in spider.start_requests():
                # 2. &#x628A;&#x521D;&#x59CB;&#x8BF7;&#x6C42;&#x6DFB;&#x52A0;&#x7ED9;&#x8C03;&#x5EA6;&#x5668;
                # &#x5229;&#x7528;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x9884;&#x5904;&#x7406;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;
                for spider_mid in self.spider_mids:
                    start_request = spider_mid.process_request(start_request)
                start_request.spider_name = spider_name  # &#x4E3A;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7ED1;&#x5B9A;&#x5B83;&#x6240;&#x5C5E;&#x7684;&#x722C;&#x866B;&#x7684;&#x540D;&#x79F0;
                self.scheduler.add_request(start_request)

    def _execute_request_response_item(self):
        &apos;&apos;&apos;&#x6839;&#x636E;&#x8BF7;&#x6C42;&#x3001;&#x53D1;&#x8D77;&#x8BF7;&#x6C42;&#x83B7;&#x53D6;&#x54CD;&#x5E94;&#x3001;&#x89E3;&#x6790;&#x54CD;&#x5E94;&#x3001;&#x5904;&#x7406;&#x54CD;&#x5E94;&#x7ED3;&#x679C;&apos;&apos;&apos;
        # 3. &#x4ECE;&#x8C03;&#x5EA6;&#x5668;&#x83B7;&#x53D6;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#xFF0C;&#x4EA4;&#x7ED9;&#x4E0B;&#x8F7D;&#x5668;&#x53D1;&#x8D77;&#x8BF7;&#x6C42;&#xFF0C;&#x83B7;&#x53D6;&#x4E00;&#x4E2A;&#x54CD;&#x5E94;&#x5BF9;&#x8C61;
        request = self.scheduler.get_request()
        if request is None:
            return
        # &#x5229;&#x7528;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x9884;&#x5904;&#x7406;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;
        for downloader_mid in self.downloader_mids:
            request = downloader_mid.process_request(request)
        # 4. &#x5229;&#x7528;&#x4E0B;&#x8F7D;&#x5668;&#x53D1;&#x8D77;&#x8BF7;&#x6C42;
        response = self.downloader.get_response(request)
        # &#x5229;&#x7528;&#x4E0B;&#x8F7D;&#x5668;&#x4E2D;&#x95F4;&#x4EF6;&#x9884;&#x5904;&#x7406;&#x54CD;&#x5E94;&#x5BF9;&#x8C61;
        for downloader_mid in self.downloader_mids:
            response = downloader_mid.process_response(response)

        spider = self.spiders[request.spider_name]  # &#x6839;&#x636E;&#x8BF7;&#x6C42;&#x7684;spider_name&#x5C5E;&#x6027;&#xFF0C;&#x83B7;&#x53D6;&#x5BF9;&#x5E94;&#x7684;&#x722C;&#x866B;&#x5BF9;&#x8C61;

        # 5. &#x5229;&#x7528;&#x722C;&#x866B;&#x7684;&#x89E3;&#x6790;&#x54CD;&#x5E94;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x5904;&#x7406;&#x54CD;&#x5E94;&#xFF0C;&#x5F97;&#x5230;&#x7ED3;&#x679C;
        parse = getattr(spider, request.parse)    # &#x83B7;&#x53D6;&#x5BF9;&#x5E94;&#x7684;&#x89E3;&#x6790;&#x51FD;&#x6570;
        results = parse(response)    # parse&#x51FD;&#x6570;&#x7684;&#x8FD4;&#x56DE;&#x503C;&#x662F;&#x4E00;&#x4E2A;&#x5BB9;&#x5668;&#xFF0C;&#x5982;&#x5217;&#x8868;&#x6216;&#x8005;&#x751F;&#x6210;&#x5668;&#x5BF9;&#x8C61;
        for result in results:
            # 6. &#x5224;&#x65AD;&#x7ED3;&#x679C;&#x5BF9;&#x8C61;
            # 6.1 &#x5982;&#x679C;&#x662F;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#xFF0C;&#x90A3;&#x4E48;&#x5C31;&#x518D;&#x4EA4;&#x7ED9;&#x8C03;&#x5EA6;&#x5668;
            if isinstance(result, Request):
                # &#x5229;&#x7528;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x9884;&#x5904;&#x7406;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;
                for spider_mid in self.spider_mids:
                    result = spider_mid.process_request(result)
                result.spider_name = request.spider_name  # &#x4E3A;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7ED1;&#x5B9A;&#x5B83;&#x6240;&#x5C5E;&#x7684;&#x722C;&#x866B;&#x7684;&#x540D;&#x79F0;
                self.scheduler.add_request(result)
            # 6.2 &#x5426;&#x5219;&#xFF0C;&#x5C31;&#x4EA4;&#x7ED9;&#x7BA1;&#x9053;&#x5904;&#x7406;
            else:
                # &#x5229;&#x7528;&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x9884;&#x5904;&#x7406;&#x6570;&#x636E;&#x5BF9;&#x8C61;
                for spider_mid in self.spider_mids:
                    result = spider_mid.process_item(result)
                for pipeline in self.pipelines:    # &#x591A;&#x4E2A;&#x7BA1;&#x9053;&#x5BF9;&#x8C61;&#xFF0C;&#x8F6E;&#x6D41;&#x5904;&#x7406;item&#x5BF9;&#x8C61;
                    result = pipeline.process_item(result, spider)

        # &#x7EDF;&#x8BA1;&#x54CD;&#x5E94;&#x603B;&#x6570;
        self.total_response_number += 1

    def _callback(self, temp):
        &apos;&apos;&apos;&#x6267;&#x884C;&#x65B0;&#x7684;&#x8BF7;&#x6C42;&#x7684;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#xFF0C;&#x5B9E;&#x73B0;&#x5FAA;&#x73AF;&apos;&apos;&apos;
        if self.running is True:  # &#x5982;&#x679C;&#x8FD8;&#x6CA1;&#x6EE1;&#x8DB3;&#x9000;&#x51FA;&#x6761;&#x4EF6;&#xFF0C;&#x90A3;&#x4E48;&#x7EE7;&#x7EED;&#x6DFB;&#x52A0;&#x65B0;&#x4EFB;&#x52A1;&#xFF0C;&#x5426;&#x5219;&#x4E0D;&#x7EE7;&#x7EED;&#x6DFB;&#x52A0;&#xFF0C;&#x7EC8;&#x6B62;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#xFF0C;&#x8FBE;&#x5230;&#x9000;&#x51FA;&#x5FAA;&#x73AF;&#x7684;&#x76EE;&#x7684;
            self.pool.apply_async(self._execute_request_response_item, callback=self._callback)

    def _start_engine(self):
        &apos;&apos;&apos;&#x4F9D;&#x6B21;&#x8C03;&#x7528;&#x5176;&#x4ED6;&#x7EC4;&#x4EF6;&#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x7684;&#x63A5;&#x53E3;&#xFF0C;&#x5B9E;&#x73B0;&#x6574;&#x4E2A;&#x6846;&#x67B6;&#x7684;&#x8FD0;&#x4F5C;(&#x9A71;&#x52A8;)&apos;&apos;&apos;
        self.running = True  # &#x542F;&#x52A8;&#x5F15;&#x64CE;&#xFF0C;&#x8BBE;&#x7F6E;&#x72B6;&#x6001;&#x4E3A;True
        # &#x5411;&#x8C03;&#x5EA6;&#x5668;&#x6DFB;&#x52A0;&#x521D;&#x59CB;&#x8BF7;&#x6C42;
        self.pool.apply_async(self._start_requests)  # &#x4F7F;&#x7528;&#x5F02;&#x6B65;

        self.pool.apply_async(self._execute_request_response_item, callback=self._callback)  # &#x5229;&#x7528;&#x56DE;&#x8C03;&#x5B9E;&#x73B0;&#x5FAA;&#x73AF;

        # &#x8BBE;&#x7F6E;&#x5FAA;&#x73AF;&#xFF0C;&#x5904;&#x7406;&#x591A;&#x4E2A;&#x8BF7;&#x6C42;
        while True:
            time.sleep(0.0001)  # &#x907F;&#x514D;cpu&#x7A7A;&#x8F6C;&#xFF0C;&#x6D88;&#x8017;&#x6027;&#x80FD;

            # &#x6839;&#x636E;&#x8BF7;&#x6C42;&#x3001;&#x53D1;&#x8D77;&#x8BF7;&#x6C42;&#x83B7;&#x53D6;&#x54CD;&#x5E94;&#x3001;&#x89E3;&#x6790;&#x54CD;&#x5E94;&#x3001;&#x5904;&#x7406;&#x54CD;&#x5E94;&#x7ED3;&#x679C;
            # self._execute_request_response_item()

            # &#x8BBE;&#x7F6E;&#x9000;&#x51FA;&#x6761;&#x4EF6;&#xFF1A;&#x5F53;&#x8BF7;&#x6C42;&#x6570;&#x548C;&#x54CD;&#x5E94;&#x6570;&#x76F8;&#x7B49;&#x65F6;&#xFF0C;&#x9000;&#x51FA;&#x5FAA;&#x73AF;
            # &#x56E0;&#x4E3A;&#x5F02;&#x6B65;&#xFF0C;&#x9700;&#x8981;&#x589E;&#x52A0;&#x5224;&#x65AD;&#xFF0C;&#x8BF7;&#x6C42;&#x6570;&#x4E0D;&#x80FD;&#x4E3A;0
            if self.total_response_number &gt;= self.scheduler.total_request_number and self.scheduler.total_request_number != 0:
                self.running = False  # &#x6EE1;&#x8DB3;&#x5FAA;&#x73AF;&#x9000;&#x51FA;&#x6761;&#x4EF6;&#x540E;&#xFF0C;&#x8BBE;&#x7F6E;&#x8FD0;&#x884C;&#x72B6;&#x6001;&#x4E3A;False
                break

        self.pool.close()
        self.pool.join()
</code></pre>
<h2 id="3-&#x5B9E;&#x73B0;&#x5F02;&#x6B65;&#x5E76;&#x53D1;&#x63A7;&#x5236;">3. &#x5B9E;&#x73B0;&#x5F02;&#x6B65;&#x5E76;&#x53D1;&#x63A7;&#x5236;</h2>
<p>&#x5728;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E2D;&#x8BBE;&#x7F6E;&#x6700;&#x5927;&#x5E76;&#x53D1;&#x6570;&#xFF0C;&#x5E76;&#x5728;&#x5F15;&#x64CE;&#x4E2D;&#x4F7F;&#x7528;</p>
<pre><code class="lang-Python"># scrapy_plus/core/engine.py
class Engine(object):

    ......

    def _start_engine(self):
        self.running = True
        &apos;&apos;&apos;&#x4F9D;&#x6B21;&#x8C03;&#x7528;&#x5176;&#x4ED6;&#x7EC4;&#x4EF6;&#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x7684;&#x63A5;&#x53E3;&#xFF0C;&#x5B9E;&#x73B0;&#x6574;&#x4E2A;&#x6846;&#x67B6;&#x7684;&#x8FD0;&#x4F5C;(&#x9A71;&#x52A8;)&apos;&apos;&apos;
        # &#x5411;&#x8C03;&#x5EA6;&#x5668;&#x6DFB;&#x52A0;&#x521D;&#x59CB;&#x8BF7;&#x6C42;
        self.pool.apply_async(self._start_requests)    # &#x4F7F;&#x7528;&#x5F02;&#x6B65;

        # &#x63A7;&#x5236;&#x6700;&#x5927;&#x5E76;&#x53D1;&#x6570;
        for i in range(settings.MAX_ASYNC_NUMBER):
            self.pool.apply_async(self._execute_request_response_item, callback=self._callback)    # &#x5229;&#x7528;&#x56DE;&#x8C03;&#x5B9E;&#x73B0;&#x5FAA;&#x73AF;

        while True:
            time.sleep(0.0001)    # &#x907F;&#x514D;cpu&#x7A7A;&#x8F6C;&#xFF0C;&#x6D88;&#x8017;&#x6027;&#x80FD;
            # &#x8BBE;&#x7F6E;&#x9000;&#x51FA;&#x6761;&#x4EF6;&#xFF1A;&#x5F53;&#x8BF7;&#x6C42;&#x6570;&#x548C;&#x54CD;&#x5E94;&#x6570;&#x76F8;&#x7B49;&#x65F6;&#xFF0C;&#x9000;&#x51FA;&#x5FAA;&#x73AF;
            # &#x56E0;&#x4E3A;&#x5F02;&#x6B65;&#xFF0C;&#x9700;&#x8981;&#x589E;&#x52A0;&#x5224;&#x65AD;&#xFF0C;&#x8BF7;&#x6C42;&#x6570;&#x4E0D;&#x80FD;&#x4E3A;0
            if self.total_response_number &gt;= self.scheduler.total_request_number and self.scheduler.total_request_number != 0:
                self.running = False    # &#x6EE1;&#x8DB3;&#x5FAA;&#x73AF;&#x9000;&#x51FA;&#x6761;&#x4EF6;&#x540E;&#xFF0C;&#x8BBE;&#x7F6E;&#x8FD0;&#x884C;&#x72B6;&#x6001;&#x4E3A;False
                break
        self.pool.close()
        self.pool.join()
</code></pre>
<h2 id="4-&#x5BF9;&#x5F02;&#x6B65;&#x4EFB;&#x52A1;&#x8FDB;&#x884C;&#x5F02;&#x5E38;&#x63A7;&#x5236;&#xFF0C;&#x589E;&#x52A0;&#x5F02;&#x5E38;&#x56DE;&#x8C03;&#x51FD;&#x6570;errorcallback">4. &#x5BF9;&#x5F02;&#x6B65;&#x4EFB;&#x52A1;&#x8FDB;&#x884C;&#x5F02;&#x5E38;&#x63A7;&#x5236;&#xFF0C;&#x589E;&#x52A0;&#x5F02;&#x5E38;&#x56DE;&#x8C03;&#x51FD;&#x6570;error_callback</h2>
<pre><code class="lang-Python"># scrapy_plus/core/engine.py
class Engine(object):

    ......

    def _callback(self, temp):
        &apos;&apos;&apos;&#x6267;&#x884C;&#x65B0;&#x7684;&#x8BF7;&#x6C42;&#x7684;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#xFF0C;&#x5B9E;&#x73B0;&#x5FAA;&#x73AF;&apos;&apos;&apos;
        if self.running is True:    # &#x5982;&#x679C;&#x8FD8;&#x6CA1;&#x6EE1;&#x8DB3;&#x9000;&#x51FA;&#x6761;&#x4EF6;&#xFF0C;&#x90A3;&#x4E48;&#x7EE7;&#x7EED;&#x6DFB;&#x52A0;&#x65B0;&#x4EFB;&#x52A1;&#xFF0C;&#x5426;&#x5219;&#x4E0D;&#x7EE7;&#x7EED;&#x6DFB;&#x52A0;&#xFF0C;&#x7EC8;&#x6B62;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#xFF0C;&#x8FBE;&#x5230;&#x9000;&#x51FA;&#x5FAA;&#x73AF;&#x7684;&#x76EE;&#x7684;
            self.pool.apply_async(self._execute_request_response_item, callback=self._callback, error_callback=self._error_callback)

    def _error_callback(self, exception):
        &apos;&apos;&apos;&#x5F02;&#x5E38;&#x56DE;&#x8C03;&#x51FD;&#x6570;&apos;&apos;&apos;
        try:
            raise exception    # &#x629B;&#x51FA;&#x5F02;&#x5E38;&#x540E;&#xFF0C;&#x624D;&#x80FD;&#x88AB;&#x65E5;&#x5FD7;&#x8FDB;&#x884C;&#x5B8C;&#x6574;&#x8BB0;&#x5F55;&#x4E0B;&#x6765;
        except Exception as e:
            logger.exception(e)

    def _start_engine(self):
        self.running = True
        &apos;&apos;&apos;&#x4F9D;&#x6B21;&#x8C03;&#x7528;&#x5176;&#x4ED6;&#x7EC4;&#x4EF6;&#x5BF9;&#x5916;&#x63D0;&#x4F9B;&#x7684;&#x63A5;&#x53E3;&#xFF0C;&#x5B9E;&#x73B0;&#x6574;&#x4E2A;&#x6846;&#x67B6;&#x7684;&#x8FD0;&#x4F5C;(&#x9A71;&#x52A8;)&apos;&apos;&apos;
        # &#x5411;&#x8C03;&#x5EA6;&#x5668;&#x6DFB;&#x52A0;&#x521D;&#x59CB;&#x8BF7;&#x6C42;
        self.pool.apply_async(self._start_requests, error_callback=self._error_callback)    # &#x4F7F;&#x7528;&#x5F02;&#x6B65;

        for i in range(settings.MAX_ASYNC_NUMBER):
            self.pool.apply_async(self._execute_request_response_item, callback=self._callback, error_callback=self._error_callback)    # &#x5229;&#x7528;&#x56DE;&#x8C03;&#x5B9E;&#x73B0;&#x5FAA;&#x73AF;

        while True:
            time.sleep(0.0001)    # &#x907F;&#x514D;cpu&#x7A7A;&#x8F6C;&#xFF0C;&#x6D88;&#x8017;&#x6027;&#x80FD;
            # &#x8BBE;&#x7F6E;&#x9000;&#x51FA;&#x6761;&#x4EF6;&#xFF1A;&#x5F53;&#x8BF7;&#x6C42;&#x6570;&#x548C;&#x54CD;&#x5E94;&#x6570;&#x76F8;&#x7B49;&#x65F6;&#xFF0C;&#x9000;&#x51FA;&#x5FAA;&#x73AF;
            # &#x56E0;&#x4E3A;&#x5F02;&#x6B65;&#xFF0C;&#x9700;&#x8981;&#x589E;&#x52A0;&#x5224;&#x65AD;&#xFF0C;&#x8BF7;&#x6C42;&#x6570;&#x4E0D;&#x80FD;&#x4E3A;0
            if self.total_response_number &gt;= self.scheduler.total_request_number and self.scheduler.total_request_number != 0:
                self.running = False    # &#x6EE1;&#x8DB3;&#x5FAA;&#x73AF;&#x9000;&#x51FA;&#x6761;&#x4EF6;&#x540E;&#xFF0C;&#x8BBE;&#x7F6E;&#x8FD0;&#x884C;&#x72B6;&#x6001;&#x4E3A;False
                break
        self.pool.close()
        self.pool.join()
</code></pre>
<h2 id="&#x5C0F;&#x7ED3;">&#x5C0F;&#x7ED3;</h2>
<ul>
<li>&#x672C;&#x5C0F;&#x7ED3;&#x91CD;&#x70B9;<ul>
<li>&#x638C;&#x63E1;&#x7EBF;&#x7A0B;&#x6C60;&#x6A21;&#x5757;&#x53CA;&#x5176;&#x65B9;&#x6CD5;&#x7684;&#x4F7F;&#x7528;</li>
<li>&#x5B8C;&#x6210;&#x4EE3;&#x7801;&#x7684;&#x91CD;&#x6784;&#xFF0C;&#x63D0;&#x9AD8;&#x6846;&#x67B6;&#x7684;&#x6574;&#x4F53;&#x6548;&#x7387;</li>
</ul>
</li>
</ul>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../../爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.html" class="navigation navigation-prev " aria-label="Previous page: 框架完善--实现请求去重"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../../爬虫框架开发/4.框架功能完善/11.框架完善--使用协程池实现异步以及并发控制.html" class="navigation navigation-next " aria-label="Next page: 框架完善--使用协程池实现异步以及并发控制"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../../gitbook/app.js"></script>

    
    <script src="../../gitbook/plugins/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-book-summary-scroll-position-saver/book-summary-scroll-position-saver.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"expandable-chapters-small":{},"prism":{"css":["prismjs/themes/prism-solarizedlight.css"]},"book-summary-scroll-position-saver":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
