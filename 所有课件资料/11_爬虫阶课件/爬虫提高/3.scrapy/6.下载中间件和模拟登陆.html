<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>下载中间件和模拟登陆 | 爬虫课程</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-prism/prism-solarizedlight.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../../爬虫提高/4.scrapy_redis/index.html" />
    
    
    <link rel="prev" href="../../爬虫提高/3.scrapy/5.crawlspider类的使用.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="2.3.6"
        data-chapter-title="下载中间件和模拟登陆"
        data-filepath="爬虫提高/3.scrapy/6.下载中间件和模拟登陆.md"
        data-basepath="../.."
        data-revision="Wed May 23 2018 13:46:54 GMT+0800 (CST)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="爬虫入门/index.html">
            
                
                    <a href="../../爬虫入门/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        爬虫入门
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="爬虫入门/1.爬虫的基础知识/index.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫的基础知识
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="爬虫入门/1.爬虫的基础知识/1.爬虫的基础概念.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/1.爬虫的基础概念.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.1.</b>
                        
                        爬虫的定义和使用场景
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="爬虫入门/1.爬虫的基础知识/2.爬虫的分类和爬虫流程.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/2.爬虫的分类和爬虫流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.2.</b>
                        
                        爬虫的分类和爬虫的流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.3" data-path="爬虫入门/1.爬虫的基础知识/3.复习http和https.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/3.复习http和https.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.3.</b>
                        
                        http和https的复习
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.1.4" data-path="爬虫入门/1.爬虫的基础知识/4.字符串相关的复习.html">
            
                
                    <a href="../../爬虫入门/1.爬虫的基础知识/4.字符串相关的复习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.4.</b>
                        
                        字符串相关的复习
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="爬虫入门/2.requests模块的使用/index.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        requests模块的使用
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="爬虫入门/2.requests模块的使用/1.requests模块的基本使用.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/1.requests模块的基本使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.1.</b>
                        
                        requests模块的基本使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="爬虫入门/2.requests模块的使用/2.requests模块的深入使用.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/2.requests模块的深入使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.2.</b>
                        
                        requests模块的深入使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="爬虫入门/2.requests模块的使用/3.requests模块处理cookie.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/3.requests模块处理cookie.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.3.</b>
                        
                        requests模块处理cookie
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="爬虫入门/2.requests模块的使用/4.requests模块的其他方法.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/4.requests模块的其他方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.4.</b>
                        
                        requests的其他方法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="爬虫入门/2.requests模块的使用/5.chrome浏览器使用方法介绍.html">
            
                
                    <a href="../../爬虫入门/2.requests模块的使用/5.chrome浏览器使用方法介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.5.</b>
                        
                        chrome浏览器使用方法介绍
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="爬虫入门/3.数据提取方法/index.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                        数据提取方法
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="爬虫入门/3.数据提取方法/1.数据提取的概念和数据分类.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/1.数据提取的概念和数据分类.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.1.</b>
                        
                        数据提取的概念和数据分类
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="爬虫入门/3.数据提取方法/2.数据提取之json.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/2.数据提取之json.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.2.</b>
                        
                        数据提取之json
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="爬虫入门/3.数据提取方法/3.数据提取之正则.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/3.数据提取之正则.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.3.</b>
                        
                        数据提取之正则
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="爬虫入门/3.数据提取方法/4.xpath和lxml类库.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/4.xpath和lxml类库.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.4.</b>
                        
                        数据提取之xpath
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="爬虫入门/3.数据提取方法/5.lxml模块的学习.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/5.lxml模块的学习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.5.</b>
                        
                        数据提取之lxml
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="爬虫入门/3.数据提取方法/6.实现更快的爬虫.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/6.实现更快的爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.6.</b>
                        
                        多进程多线程爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="爬虫入门/3.数据提取方法/7.实现更快的爬虫（二）.html">
            
                
                    <a href="../../爬虫入门/3.数据提取方法/7.实现更快的爬虫（二）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.7.</b>
                        
                        通过线程池实现爬虫
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="爬虫提高/index.html">
            
                
                    <a href="../../爬虫提高/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        爬虫提高
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="爬虫提高/1.selenium/index.html">
            
                
                    <a href="../../爬虫提高/1.selenium/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        selenium的学习
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="爬虫提高/1.selenium/1.常见的反爬手段和解决思路.html">
            
                
                    <a href="../../爬虫提高/1.selenium/1.常见的反爬手段和解决思路.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.1.</b>
                        
                        常见的反爬手段和解决思路
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="爬虫提高/1.selenium/2.selenium的使用.html">
            
                
                    <a href="../../爬虫提高/1.selenium/2.selenium的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.2.</b>
                        
                        selenium的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="爬虫提高/1.selenium/3.打码平台的使用.html">
            
                
                    <a href="../../爬虫提高/1.selenium/3.打码平台的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.3.</b>
                        
                        打码平台的使用
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="爬虫提高/2.MONGODB数据库/index.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.</b>
                        
                        MONGODB数据库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.2.1" data-path="爬虫提高/2.MONGODB数据库/1.mongodb的介绍和安装.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/1.mongodb的介绍和安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.1.</b>
                        
                        mongodb的介绍和安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.2" data-path="爬虫提高/2.MONGODB数据库/2.mongodb的基本使用.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/2.mongodb的基本使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.2.</b>
                        
                        mongodb的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.3" data-path="爬虫提高/2.MONGODB数据库/3.mongodb的聚合操作.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/3.mongodb的聚合操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.3.</b>
                        
                        mongodb的聚合操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.4" data-path="爬虫提高/2.MONGODB数据库/4.mongodb的索引和备份恢复.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/4.mongodb的索引和备份恢复.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.4.</b>
                        
                        mongodb的索引和备份恢复
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.2.5" data-path="爬虫提高/2.MONGODB数据库/5.mongodb和python的交互.html">
            
                
                    <a href="../../爬虫提高/2.MONGODB数据库/5.mongodb和python的交互.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.2.5.</b>
                        
                        mongodb和python交互
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="爬虫提高/3.scrapy/index.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.</b>
                        
                        scrapy框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="爬虫提高/3.scrapy/1.scrapy的基础概念和流程.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/1.scrapy的基础概念和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.1.</b>
                        
                        scrapy的基础概念和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="爬虫提高/3.scrapy/2.scrapy的入门使用（一）.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/2.scrapy的入门使用（一）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.2.</b>
                        
                        scrapy的入门使用(一)
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.3" data-path="爬虫提高/3.scrapy/3.scrapy的入门使用（二）.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/3.scrapy的入门使用（二）.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.3.</b>
                        
                        scrapy的入门使用(二)
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.4" data-path="爬虫提高/3.scrapy/4.scrapy的深入使用.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/4.scrapy的深入使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.4.</b>
                        
                        scrapy的深入使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.3.5" data-path="爬虫提高/3.scrapy/5.crawlspider类的使用.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/5.crawlspider类的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.5.</b>
                        
                        crawlspider类的使用
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="2.3.6" data-path="爬虫提高/3.scrapy/6.下载中间件和模拟登陆.html">
            
                
                    <a href="../../爬虫提高/3.scrapy/6.下载中间件和模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.3.6.</b>
                        
                        下载中间件和模拟登陆
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="爬虫提高/4.scrapy_redis/index.html">
            
                
                    <a href="../../爬虫提高/4.scrapy_redis/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.</b>
                        
                        scrapy_redis
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.4.1" data-path="爬虫提高/4.scrapy_redis/1.scrapy_redis实现增量式爬虫.html">
            
                
                    <a href="../../爬虫提高/4.scrapy_redis/1.scrapy_redis实现增量式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.1.</b>
                        
                        scrapy_redis实现增量式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.2" data-path="爬虫提高/4.scrapy_redis/2.scrapy_redis实现分布式爬虫.html">
            
                
                    <a href="../../爬虫提高/4.scrapy_redis/2.scrapy_redis实现分布式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.2.</b>
                        
                        scrapy_redis实现分布式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2.4.3" data-path="爬虫提高/4.scrapy_redis/3.crontab爬虫定时启动.html">
            
                
                    <a href="../../爬虫提高/4.scrapy_redis/3.crontab爬虫定时启动.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.4.3.</b>
                        
                        crontab爬虫定时启动
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="爬虫框架开发/index.html">
            
                
                    <a href="../../爬虫框架开发/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        爬虫框架开发
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="爬虫框架开发/1.爬虫框架开发分析/index.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        爬虫框架开发分析
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="爬虫框架开发/1.爬虫框架开发分析/1.了解框架.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/1.了解框架.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.1.</b>
                        
                        了解框架
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="爬虫框架开发/1.爬虫框架开发分析/2.框架设计思路分析.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/2.框架设计思路分析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.2.</b>
                        
                        框架设计思路分析
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="爬虫框架开发/1.爬虫框架开发分析/3.框架代码雏形结构.html">
            
                
                    <a href="../../爬虫框架开发/1.爬虫框架开发分析/3.框架代码雏形结构.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.3.</b>
                        
                        雏形代码结构
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="爬虫框架开发/2.框架雏形实现/index.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        框架雏形实现
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.2.1" data-path="爬虫框架开发/2.框架雏形实现/1.框架雏形--http模块和item模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/1.框架雏形--http模块和item模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.1.</b>
                        
                        框架雏形--http模块和item模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.2" data-path="爬虫框架开发/2.框架雏形实现/2.框架雏形--核心模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/2.框架雏形--核心模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.2.</b>
                        
                        框架雏形--核心模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.3" data-path="爬虫框架开发/2.框架雏形实现/3.框架安装.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/3.框架安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.3.</b>
                        
                        框架安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.4" data-path="爬虫框架开发/2.框架雏形实现/4.框架运行--main.py.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/4.框架运行--main.py.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.4.</b>
                        
                        框架运行--main.py
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2.5" data-path="爬虫框架开发/2.框架雏形实现/5.框架雏形--中间件模块.html">
            
                
                    <a href="../../爬虫框架开发/2.框架雏形实现/5.框架雏形--中间件模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.5.</b>
                        
                        框架雏形--中间件
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="爬虫框架开发/4.框架功能完善/index.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        框架功能完善
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1" data-path="爬虫框架开发/4.框架功能完善/1.框架完善--日志模块使用.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/1.框架完善--日志模块使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.1.</b>
                        
                        框架完善--日志模块使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.2" data-path="爬虫框架开发/4.框架功能完善/2.框架完善--配置文件实现.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/2.框架完善--配置文件实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.2.</b>
                        
                        框架完善--配置文件实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.3" data-path="爬虫框架开发/4.框架功能完善/3.框架完善--多爬虫实现之一--多请求.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/3.框架完善--多爬虫实现之一--多请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.3.</b>
                        
                        框架完善--多爬虫实现之一--多请求
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.4" data-path="爬虫框架开发/4.框架功能完善/4.框架完善--多爬虫实现之二--多个解析函数.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/4.框架完善--多爬虫实现之二--多个解析函数.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.4.</b>
                        
                        框架完善--多爬虫实现之二--多个解析函数
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.5" data-path="爬虫框架开发/4.框架功能完善/5.框架完善--多爬虫实现之三--多爬虫文件.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/5.框架完善--多爬虫实现之三--多爬虫文件.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.5.</b>
                        
                        框架完善--多爬虫实现之三--多爬虫文件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.6" data-path="爬虫框架开发/4.框架功能完善/6.框架完善--实现多个管道.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/6.框架完善--实现多个管道.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.6.</b>
                        
                        框架完善--实现多个管道
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.7" data-path="爬虫框架开发/4.框架功能完善/7.框架完善--实现多个中间件.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/7.框架完善--实现多个中间件.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.7.</b>
                        
                        框架完善--实现多个中间件
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.8" data-path="爬虫框架开发/4.框架功能完善/8.框架完善--实现动态模块导入.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/8.框架完善--实现动态模块导入.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.8.</b>
                        
                        框架完善--实现动态模块导入
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.9" data-path="爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/9.框架完善--实现请求去重.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.9.</b>
                        
                        框架完善--实现请求去重
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.10" data-path="爬虫框架开发/4.框架功能完善/10.框架完善--使用线程池实现异步以及并发控制.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/10.框架完善--使用线程池实现异步以及并发控制.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.10.</b>
                        
                        框架完善--使用线程池实现异步以及并发控制
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3.11" data-path="爬虫框架开发/4.框架功能完善/11.框架完善--使用协程池实现异步以及并发控制.html">
            
                
                    <a href="../../爬虫框架开发/4.框架功能完善/11.框架完善--使用协程池实现异步以及并发控制.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.11.</b>
                        
                        框架完善--使用协程池实现异步以及并发控制
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="爬虫框架开发/5.框架功能升级/index.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.</b>
                        
                        框架功能升级
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.4.1" data-path="爬虫框架开发/5.框架功能升级/1.框架升级--分布式爬虫设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/1.框架升级--分布式爬虫设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.1.</b>
                        
                        框架升级--分布式爬虫设计原理及其实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4.2" data-path="爬虫框架开发/5.框架功能升级/2.框架升级--增量爬虫设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/2.框架升级--增量爬虫设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.2.</b>
                        
                        框架升级--增量爬虫设计原理及其实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4.3" data-path="爬虫框架开发/5.框架功能升级/3.框架升级--断点续爬设计原理及其实现.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/3.框架升级--断点续爬设计原理及其实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.3.</b>
                        
                        框架升级--断点续爬设计原理及其实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.4.4" data-path="爬虫框架开发/5.框架功能升级/4.框架可以改进的内容.html">
            
                
                    <a href="../../爬虫框架开发/5.框架功能升级/4.框架可以改进的内容.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.4.4.</b>
                        
                        框架升级--框架可以改进的内容
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="爬虫框架开发/6.项目实战/index.html">
            
                
                    <a href="../../爬虫框架开发/6.项目实战/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.5.</b>
                        
                        项目实战
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="扩展阅读/index.html">
            
                
                    <a href="../../扩展阅读/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        扩展阅读
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="扩展阅读/1.ascii和unicode以及utf-8.html">
            
                
                    <a href="../../扩展阅读/1.ascii和unicode以及utf-8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        ascii、unicode和utf-8的起源
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="扩展阅读/charles使用指南.html">
            
                
                    <a href="../../扩展阅读/charles使用指南.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        charles使用指南
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="参考代码/index.html">
            
                
                    <a href="../../参考代码/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        参考代码
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="参考代码/python爬虫中多线程多进程代码实现.html">
            
                
                    <a href="../../参考代码/python爬虫中多线程多进程代码实现.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        爬虫中多线程多进程代码实现
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="参考代码/云打码.html">
            
                
                    <a href="../../参考代码/云打码.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        云打码的使用
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../" >爬虫课程</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x548C;&#x6A21;&#x62DF;&#x767B;&#x9646;">&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x548C;&#x6A21;&#x62DF;&#x767B;&#x9646;</h1>
<h2 id="&#x76EE;&#x6807;">&#x76EE;&#x6807;</h2>
<ul>
<li>&#x638C;&#x63E1;&#x5E38;&#x89C1;&#x7684;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x7F16;&#x5199;&#x65B9;&#x5F0F;</li>
<li>&#x638C;&#x63E1;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#x601D;&#x8DEF;</li>
<li>&#x638C;&#x63E1;scrapy&#x4E2D;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#x4E09;&#x79CD;&#x65B9;&#x5F0F;</li>
</ul>
<h2 id="1-scrapy&#x4E2D;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;">1. scrapy&#x4E2D;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;</h2>
<ol>
<li><p>&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#xFF1A;</p>
<p> &#x7F16;&#x5199;&#x4E00;&#x4E2A;<code>Downloader Middlewares</code>&#x548C;&#x6211;&#x4EEC;&#x7F16;&#x5199;&#x4E00;&#x4E2A;pipeline&#x4E00;&#x6837;&#xFF0C;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;&#x7C7B;&#xFF0C;&#x7136;&#x540E;&#x5728;setting&#x4E2D;&#x5F00;&#x542F;</p>
</li>
<li><p><code>Downloader Middlewares</code>&#x9ED8;&#x8BA4;&#x7684;&#x65B9;&#x6CD5;&#xFF1A;</p>
<ul>
<li><p>process_request(self, request, spider)&#xFF1A;</p>
<ul>
<li>&#x5F53;&#x6BCF;&#x4E2A;request&#x901A;&#x8FC7;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x65F6;&#xFF0C;&#x8BE5;&#x65B9;&#x6CD5;&#x88AB;&#x8C03;&#x7528;&#x3002;</li>
<li>&#x8FD4;&#x56DE;None&#x503C;&#xFF1A;&#x7EE7;&#x7EED;&#x8BF7;&#x6C42;</li>
<li>&#x8FD4;&#x56DE;Response&#x5BF9;&#x8C61;&#xFF1A;&#x4E0D;&#x5728;&#x8BF7;&#x6C42;&#xFF0C;&#x628A;response&#x8FD4;&#x56DE;&#x7ED9;&#x5F15;&#x64CE;</li>
<li>&#x8FD4;&#x56DE;Request&#x5BF9;&#x8C61;&#xFF1A;&#x628A;request&#x5BF9;&#x8C61;&#x4EA4;&#x7ED9;&#x8C03;&#x5EA6;&#x5668;&#x8FDB;&#x884C;&#x540E;&#x7EED;&#x7684;&#x8BF7;&#x6C42;</li>
</ul>
</li>
<li><p>process_response(self, request, response, spider)&#xFF1A;</p>
<pre><code> - &#x5F53;&#x4E0B;&#x8F7D;&#x5668;&#x5B8C;&#x6210;http&#x8BF7;&#x6C42;&#xFF0C;&#x4F20;&#x9012;&#x54CD;&#x5E94;&#x7ED9;&#x5F15;&#x64CE;&#x7684;&#x65F6;&#x5019;&#x8C03;&#x7528;
 - &#x8FD4;&#x56DE;Resposne&#xFF1A;&#x4EA4;&#x7ED9;process_response&#x6765;&#x5904;&#x7406;
 - &#x8FD4;&#x56DE;Request&#x5BF9;&#x8C61;&#xFF1A;&#x4EA4;&#x7ED9;&#x8C03;&#x53D6;&#x5668;&#x7EE7;&#x7EED;&#x8BF7;&#x6C42;
</code></pre></li>
</ul>
</li>
<li><p>&#x5B9A;&#x4E49;&#x5B9E;&#x73B0;&#x968F;&#x673A;User-Agent&#x7684;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;</p>
<pre><code class="lang-python"> <span class="token keyword">class</span> <span class="token class-name">UserAgentMiddleware</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
     <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>request<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
         agent <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>agents<span class="token punctuation">)</span>
         request<span class="token punctuation">.</span>headers<span class="token punctuation">[</span><span class="token string">&apos;User-Agent&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> agent
</code></pre>
</li>
<li><p>&#x5B9A;&#x4E49;&#x5B9E;&#x73B0;&#x968F;&#x673A;&#x4F7F;&#x7528;&#x4EE3;&#x7406;&#x7684;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;</p>
<pre><code class="lang-pyhton"> class ProxyMiddleware(object):
     def process_request(self,request,spider):
         proxy = random.choice(proxies)
         request.meta[&apos;proxy&apos;] = proxy
</code></pre>
<p> User-Agent&#x6C60;&#x5728;&#x8FD9;&#x91CC;</p>
<pre><code> ```python
 USER_AGENTS = [ &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)&quot;, &quot;Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)&quot;, &quot;Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)&quot;, &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)&quot;, &quot;Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6&quot;, &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1&quot;, &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0&quot;, &quot;Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5&quot; ]
 ```
</code></pre></li>
</ol>
<h2 id="2-&#x4F7F;&#x7528;scrapy&#x8FDB;&#x884C;&#x6A21;&#x62DF;&#x767B;&#x9646;">2. &#x4F7F;&#x7528;scrapy&#x8FDB;&#x884C;&#x6A21;&#x62DF;&#x767B;&#x9646;</h2>
<h3 id="21-&#x56DE;&#x987E;&#x4E4B;&#x524D;&#x7684;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#x65B9;&#x6CD5;">2.1 &#x56DE;&#x987E;&#x4E4B;&#x524D;&#x7684;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#x65B9;&#x6CD5;</h3>
<ol>
<li><p>requests&#x662F;&#x5982;&#x4F55;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#xFF1F;</p>
<ol>
<li>&#x76F4;&#x63A5;&#x643A;&#x5E26;cookies&#x8BF7;&#x6C42;&#x9875;&#x9762;</li>
<li>&#x627E;&#x63A5;&#x53E3;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#x5B58;&#x50A8;cookie</li>
</ol>
</li>
<li><p>selenium&#x662F;&#x5982;&#x4F55;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x7684;&#xFF1F;</p>
<ol>
<li>&#x627E;&#x5230;&#x5BF9;&#x5E94;&#x7684;input&#x6807;&#x7B7E;&#xFF0C;&#x8F93;&#x5165;&#x6587;&#x5B57;&#x70B9;&#x51FB;&#x767B;&#x5F55;</li>
</ol>
</li>
</ol>
<p>scrapy&#x6765;&#x8BF4;&#xFF0C;&#x6709;&#x4E24;&#x4E2A;&#x65B9;&#x6CD5;&#x6A21;&#x62DF;&#x767B;&#x9646;&#xFF1A;</p>
<pre><code>1&#x3001;&#x76F4;&#x63A5;&#x643A;&#x5E26;cookie
2&#x3001;&#x627E;&#x5230;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#x7684;url&#x5730;&#x5740;&#xFF0C;&#x5E26;&#x4E0A;&#x4FE1;&#x606F;&#xFF0C;&#x53D1;&#x9001;&#x8BF7;&#x6C42;
</code></pre><h3 id="22-scrapy&#x643A;&#x5E26;cookie&#x8FDB;&#x884C;&#x6A21;&#x62DF;&#x767B;&#x9646;">2.2 scrapy&#x643A;&#x5E26;cookie&#x8FDB;&#x884C;&#x6A21;&#x62DF;&#x767B;&#x9646;</h3>
<ol>
<li><p>&#x643A;&#x5E26;cookie&#x8FDB;&#x884C;&#x6A21;&#x62DF;&#x767B;&#x9646;&#x5E94;&#x7528;&#x573A;&#x666F;&#xFF1A;</p>
<ol>
<li>cookie&#x8FC7;&#x671F;&#x65F6;&#x95F4;&#x5F88;&#x957F;&#xFF0C;&#x5E38;&#x89C1;&#x4E8E;&#x4E00;&#x4E9B;&#x4E0D;&#x89C4;&#x8303;&#x7684;&#x7F51;&#x7AD9;</li>
<li>&#x80FD;&#x5728;cookie&#x8FC7;&#x671F;&#x4E4B;&#x524D;&#x628A;&#x641C;&#x6709;&#x7684;&#x6570;&#x636E;&#x62FF;&#x5230;</li>
<li>&#x914D;&#x5408;&#x5176;&#x4ED6;&#x7A0B;&#x5E8F;&#x4F7F;&#x7528;&#xFF0C;&#x6BD4;&#x5982;&#x5176;&#x4F7F;&#x7528;selenium&#x628A;&#x767B;&#x9646;&#x4E4B;&#x540E;&#x7684;cookie&#x83B7;&#x53D6;&#x5230;&#x4FDD;&#x5B58;&#x5230;&#x672C;&#x5730;&#xFF0C;scrapy&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#x4E4B;&#x524D;&#x5148;&#x8BFB;&#x53D6;&#x672C;&#x5730;cookie</li>
</ol>
</li>
<li><p>scrapy&#x7684;start_requests&#x65B9;&#x6CD5;&#x7684;&#x5B66;&#x4E60;</p>
<p> scrapy&#x4E2D;start_url&#x662F;&#x901A;&#x8FC7;start_requests&#x6765;&#x8FDB;&#x884C;&#x5904;&#x7406;&#x7684;&#xFF0C;&#x5176;&#x5B9E;&#x73B0;&#x4EE3;&#x7801;&#x5982;&#x4E0B;</p>
<pre><code class="lang-python"> <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
     cls <span class="token operator">=</span> self<span class="token punctuation">.</span>__class__
     <span class="token keyword">if</span> method_is_overridden<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> Spider<span class="token punctuation">,</span> <span class="token string">&apos;make_requests_from_url&apos;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
         warnings<span class="token punctuation">.</span>warn<span class="token punctuation">(</span>
             <span class="token string">&quot;Spider.make_requests_from_url method is deprecated; it &quot;</span>
             <span class="token string">&quot;won&apos;t be called in future Scrapy releases. Please &quot;</span>
             <span class="token string">&quot;override Spider.start_requests method instead (see %s.%s).&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>
                 cls<span class="token punctuation">.</span>__module__<span class="token punctuation">,</span> cls<span class="token punctuation">.</span>__name__
             <span class="token punctuation">)</span><span class="token punctuation">,</span>
         <span class="token punctuation">)</span>
         <span class="token keyword">for</span> url <span class="token keyword">in</span> self<span class="token punctuation">.</span>start_urls<span class="token punctuation">:</span>
             <span class="token keyword">yield</span> self<span class="token punctuation">.</span>make_requests_from_url<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
     <span class="token keyword">else</span><span class="token punctuation">:</span>
         <span class="token keyword">for</span> url <span class="token keyword">in</span> self<span class="token punctuation">.</span>start_urls<span class="token punctuation">:</span>
             <span class="token keyword">yield</span> Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> dont_filter<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre>
<p> &#x6240;&#x4EE5;&#x5BF9;&#x5E94;&#x7684;&#xFF0C;&#x5982;&#x679C;start_url&#x5730;&#x5740;&#x4E2D;&#x7684;url&#x662F;&#x9700;&#x8981;&#x767B;&#x5F55;&#x540E;&#x624D;&#x80FD;&#x8BBF;&#x95EE;&#x7684;url&#x5730;&#x5740;&#xFF0C;&#x5219;&#x9700;&#x8981;&#x91CD;&#x5199;<code>start_request</code>&#x65B9;&#x6CD5;&#x5E76;&#x5728;&#x5176;&#x4E2D;&#x624B;&#x52A8;&#x6DFB;&#x52A0;&#x4E0A;cookie    </p>
</li>
<li><p>&#x5B9E;&#x73B0;&#x643A;&#x5E26;cookie&#x767B;&#x5F55;&#x4EBA;&#x4EBA;&#x7F51;</p>
</li>
</ol>
<p>&#x6CE8;&#x610F;&#xFF1A;scrapy&#x4E2D;cookie&#x4E0D;&#x80FD;&#x591F;&#x653E;&#x5728;headers&#x4E2D;&#xFF0C;&#x5728;&#x6784;&#x9020;&#x8BF7;&#x6C42;&#x7684;&#x65F6;&#x5019;&#x6709;&#x4E13;&#x95E8;&#x7684;cookies&#x53C2;&#x6570;&#xFF0C;&#x80FD;&#x591F;&#x63A5;&#x53D7;&#x5B57;&#x5178;&#x5F62;&#x5F0F;&#x7684;coookie</p>
<pre><code class="lang-python"><span class="token keyword">import</span> scrapy
<span class="token keyword">import</span> re

<span class="token keyword">class</span> <span class="token class-name">RenrenSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&apos;renren&apos;</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&apos;renren.com&apos;</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&apos;http://www.renren.com/941954027/profile&apos;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        cookie_str <span class="token operator">=</span> <span class="token string">&quot;cookie_str&quot;</span>
        cookie_dict <span class="token operator">=</span> <span class="token punctuation">{</span>i<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;=&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>i<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;=&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> cookie_str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>start_urls<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">,</span>
            cookies<span class="token operator">=</span>cookie_dict<span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># headers={&quot;Cookie&quot;:cookie_str}</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ret <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">&quot;&#x65B0;&#x7528;&#x6237;287&quot;</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>ret<span class="token punctuation">)</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>
            <span class="token string">&quot;http://www.renren.com/941954027/profile?v=info_timeline&quot;</span><span class="token punctuation">,</span>
            callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_detail
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ret <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">&quot;&#x65B0;&#x7528;&#x6237;287&quot;</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>ret<span class="token punctuation">)</span>
</code></pre>
<ol>
<li><p>&#x5728;settings&#x4E2D;&#x5F00;&#x542F;cookie_debug</p>
<p> &#x5728;settings.py&#x4E2D;&#x901A;&#x8FC7;&#x8BBE;&#x7F6E;<code>COOKIES_DEBUG=TRUE</code> &#x80FD;&#x591F;&#x5728;&#x7EC8;&#x7AEF;&#x770B;&#x5230;cookie&#x7684;&#x4F20;&#x9012;&#x4F20;&#x9012;&#x8FC7;&#x7A0B;</p>
<p> <img src="../images/cookie_debug.png" width="80%"></p>
</li>
</ol>
<h3 id="23-scrapy&#x53D1;&#x9001;post&#x8BF7;&#x6C42;">2.3 scrapy&#x53D1;&#x9001;post&#x8BF7;&#x6C42;</h3>
<ol>
<li><p>scrapy&#x4E2D;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#x7684;&#x65B9;&#x6CD5;
 &#x901A;&#x8FC7;<code>scrapy.FormRequest</code>&#x80FD;&#x591F;&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#xFF0C;&#x540C;&#x65F6;&#x9700;&#x8981;&#x6DFB;&#x52A0;<code>fromdata</code>&#x53C2;&#x6570;&#x4F5C;&#x4E3A;&#x8BF7;&#x6C42;&#x4F53;&#xFF0C;&#x4EE5;&#x53CA;<code>callback</code></p>
<pre><code class="lang-python"> <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>FormRequest<span class="token punctuation">(</span>
             <span class="token string">&quot;https://github.com/session&quot;</span><span class="token punctuation">,</span>
             formdata<span class="token operator">=</span><span class="token punctuation">{</span>
                 <span class="token string">&quot;authenticity_token&quot;</span><span class="token punctuation">:</span>authenticity_token<span class="token punctuation">,</span>
                 <span class="token string">&quot;utf8&quot;</span><span class="token punctuation">:</span>utf8<span class="token punctuation">,</span>
                 <span class="token string">&quot;commit&quot;</span><span class="token punctuation">:</span>commit<span class="token punctuation">,</span>
                 <span class="token string">&quot;login&quot;</span><span class="token punctuation">:</span><span class="token string">&quot;noobpythoner&quot;</span><span class="token punctuation">,</span>
                 <span class="token string">&quot;password&quot;</span><span class="token punctuation">:</span><span class="token string">&quot;zhoudawei123&quot;</span>
             <span class="token punctuation">}</span><span class="token punctuation">,</span>
             callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_login
         <span class="token punctuation">)</span>
</code></pre>
</li>
<li><p>&#x4F7F;&#x7528;scrapy&#x6A21;&#x62DF;&#x767B;&#x9646;github</p>
<p> &#x601D;&#x8DEF;&#x5206;&#x6790;</p>
<ol>
<li><p>&#x627E;&#x5230;post&#x7684;url&#x5730;&#x5740;</p>
<p> &#x70B9;&#x51FB;&#x767B;&#x5F55;&#x6309;&#x94AE;&#x8FDB;&#x884C;&#x6293;&#x5305;&#xFF0C;&#x7136;&#x540E;&#x5B9A;&#x4F4D;url&#x5730;&#x5740;&#x4E3A;<code>https://github.com/session</code></p>
</li>
<li><p>&#x627E;&#x5230;&#x8BF7;&#x6C42;&#x4F53;&#x7684;&#x89C4;&#x5F8B;</p>
<p> &#x5206;&#x6790;post&#x8BF7;&#x6C42;&#x7684;&#x8BF7;&#x6C42;&#x4F53;&#xFF0C;&#x5176;&#x4E2D;&#x5305;&#x542B;&#x7684;&#x53C2;&#x6570;&#x5747;&#x5728;&#x524D;&#x4E00;&#x6B21;&#x7684;&#x54CD;&#x5E94;&#x4E2D;</p>
</li>
<li><p>&#x9A8C;&#x8BC1;&#x662F;&#x5426;&#x767B;&#x5F55;&#x6210;&#x529F;</p>
<p> &#x901A;&#x8FC7;&#x8BF7;&#x6C42;&#x4E2A;&#x4EBA;&#x4E3B;&#x9875;&#xFF0C;&#x89C2;&#x5BDF;&#x662F;&#x5426;&#x5305;&#x542B;&#x7528;&#x6237;&#x540D;</p>
<p>&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre><code class="lang-python"><span class="token comment" spellcheck="true">#spider/github.py</span>
<span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">import</span> re

<span class="token keyword">class</span> <span class="token class-name">GithubSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
 name <span class="token operator">=</span> <span class="token string">&apos;github&apos;</span>
 allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&apos;github.com&apos;</span><span class="token punctuation">]</span>
 start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&apos;https://github.com/login&apos;</span><span class="token punctuation">]</span>

 <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
     authenticity_token <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//input[@name=&apos;authenticity_token&apos;]/@value&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
     utf8 <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//input[@name=&apos;utf8&apos;]/@value&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
     commit <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//input[@name=&apos;commit&apos;]/@value&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

     <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>FormRequest<span class="token punctuation">(</span>
         <span class="token string">&quot;https://github.com/session&quot;</span><span class="token punctuation">,</span>
         formdata<span class="token operator">=</span><span class="token punctuation">{</span>
             <span class="token string">&quot;authenticity_token&quot;</span><span class="token punctuation">:</span>authenticity_token<span class="token punctuation">,</span>
             <span class="token string">&quot;utf8&quot;</span><span class="token punctuation">:</span>utf8<span class="token punctuation">,</span>
             <span class="token string">&quot;commit&quot;</span><span class="token punctuation">:</span>commit<span class="token punctuation">,</span>
             <span class="token string">&quot;login&quot;</span><span class="token punctuation">:</span><span class="token string">&quot;noobpythoner&quot;</span><span class="token punctuation">,</span>
             <span class="token string">&quot;password&quot;</span><span class="token punctuation">:</span><span class="token string">&quot;***&quot;</span>
         <span class="token punctuation">}</span><span class="token punctuation">,</span>
         callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_login
     <span class="token punctuation">)</span>

 <span class="token keyword">def</span> <span class="token function">parse_login</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
     ret <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">&quot;noobpythoner&quot;</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span>re<span class="token punctuation">.</span>I<span class="token punctuation">)</span>
     <span class="token keyword">print</span><span class="token punctuation">(</span>ret<span class="token punctuation">)</span>
</code></pre>
</li>
</ol>
</li>
</ol>
<h3 id="23-scrapy&#x8FDB;&#x884C;&#x8868;&#x5355;&#x63D0;&#x4EA4;">2.3 scrapy&#x8FDB;&#x884C;&#x8868;&#x5355;&#x63D0;&#x4EA4;</h3>
<ol>
<li><p>&#x65B9;&#x6CD5;&#x4ECB;&#x7ECD;</p>
<p> scrapy&#x4E2D;&#x5177;&#x6709;&#x4E00;&#x4E2A;&#x65B9;&#x6CD5;&#xFF1A;<code>scrapy.Formrequest.from_response</code>&#x80FD;&#x591F;&#x81EA;&#x52A8;&#x7684;&#x4ECE;&#x54CD;&#x5E94;&#x4E2D;&#x5BFB;&#x627E;form&#x8868;&#x5355;&#xFF0C;&#x7136;&#x540E;&#x628A;formdata&#x4E2D;&#x7684;&#x6570;&#x636E;&#x63D0;&#x4EA4;&#x5230;action&#x5BF9;&#x5E94;&#x7684;url&#x5730;&#x5740;&#x4E2D;</p>
<p> &#x4F7F;&#x7528;&#x5B9E;&#x4F8B;&#x5982;&#x4E0B;</p>
<pre><code class="lang-python">  <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
     <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>FormRequest<span class="token punctuation">.</span>from_response<span class="token punctuation">(</span>
         response<span class="token punctuation">,</span><span class="token comment" spellcheck="true">#&#x81EA;&#x52A8;&#x7684;&#x4ECE;&#x4E2D;&#x5BFB;&#x627E;action&#x5BF9;&#x5E94;&#x7684;url&#x5730;&#x5740;</span>
         formdata<span class="token operator">=</span><span class="token punctuation">{</span>
             <span class="token string">&quot;login&quot;</span><span class="token punctuation">:</span><span class="token string">&quot;noobpythoner&quot;</span><span class="token punctuation">,</span>
             <span class="token string">&quot;password&quot;</span><span class="token punctuation">:</span><span class="token string">&quot;***&quot;</span>
         <span class="token punctuation">}</span><span class="token punctuation">,</span>
         callback <span class="token operator">=</span> self<span class="token punctuation">.</span>parse_login
     <span class="token punctuation">)</span>
</code></pre>
</li>
<li><p>&#x4F7F;&#x7528;<code>scrapy.Formrequest.from_response</code>&#x8FDB;&#x884C;&#x6A21;&#x62DF;&#x767B;&#x9646;github</p>
</li>
</ol>
<h2 id="&#x5C0F;&#x7ED3;">&#x5C0F;&#x7ED3;</h2>
<ul>
<li>&#x672C;&#x5C0F;&#x7ED3;&#x91CD;&#x70B9;<ul>
<li>&#x638C;&#x63E1;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;&#x65B9;&#x5F0F;</li>
<li>&#x4E86;&#x89E3;&#x4E2D;&#x95F4;&#x4EF6;&#x4E2D;&#x7684;&#x65B9;&#x6CD5;&#x548C;&#x8FD4;&#x56DE;&#x503C;</li>
<li>&#x638C;&#x63E1;scrapy&#x643A;&#x5E26;cookie&#x8FDB;&#x884C;&#x767B;&#x5F55;&#x7684;&#x65B9;&#x6CD5;</li>
<li>&#x638C;&#x63E1;scrapy&#x53D1;&#x9001;post&#x8BF7;&#x6C42;&#x7684;&#x65B9;&#x6CD5;</li>
<li>&#x638C;&#x63E1;scrapy&#x8FDB;&#x884C;&#x8868;&#x5355;&#x63D0;&#x4EA4;&#x7684;&#x65B9;&#x6CD5;</li>
</ul>
</li>
</ul>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../../爬虫提高/3.scrapy/5.crawlspider类的使用.html" class="navigation navigation-prev " aria-label="Previous page: crawlspider类的使用"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../../爬虫提高/4.scrapy_redis/index.html" class="navigation navigation-next " aria-label="Next page: scrapy_redis"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../../gitbook/app.js"></script>

    
    <script src="../../gitbook/plugins/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-book-summary-scroll-position-saver/book-summary-scroll-position-saver.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-livereload/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"expandable-chapters-small":{},"prism":{"css":["prismjs/themes/prism-solarizedlight.css"]},"book-summary-scroll-position-saver":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"livereload":{}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
